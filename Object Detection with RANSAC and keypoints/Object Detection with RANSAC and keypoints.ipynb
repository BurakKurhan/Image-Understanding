{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ä°smail Burak Kurhan\n",
    "#220201055\n",
    "import numpy as np\n",
    "import cv2\n",
    "from random import randint\n",
    "import math\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def findInlier(homography,l_kp1,l_kp2):\n",
    "    returnSrc=[]\n",
    "    returnDst=[]\n",
    "    distance=3.0\n",
    "    temp=0\n",
    "    control =[]\n",
    "    for x in range(len(l_kp1)):\n",
    "      \n",
    "        pointsList=np.dot(homography,np.array([[l_kp1[x][0]],[l_kp1[x][1]],[1]]))\n",
    "        pointsList[0]=pointsList[0]/pointsList[2]\n",
    "        pointsList[1]=pointsList[1]/pointsList[2]\n",
    "        pointsList=np.array(pointsList)\n",
    "     \n",
    "        flag = False\n",
    "        for y in range(len(l_kp2)):\n",
    "            d=float(math.sqrt((pointsList[0]-l_kp2[y][0])**2+(pointsList[1]-l_kp2[y][1])**2))\n",
    "            if (d<3.0):\n",
    "                if (distance>d):\n",
    "                    distance=d\n",
    "                    temp=y\n",
    "                    flag = True\n",
    "        if flag == True:\n",
    "            if ( temp not in control):    \n",
    "                returnSrc.append((l_kp1[x]))\n",
    "                returnDst.append((l_kp2[temp]))\n",
    "                control.append(temp)      \n",
    "    return np.array(returnSrc),np.array(returnDst)\n",
    "\n",
    "\n",
    "def dlt(src_points,dst_points):\n",
    "    Average_x_1 =0\n",
    "    Average_y_1 =0\n",
    "    Average_x_2 =0\n",
    "    Average_y_2 =0\n",
    "\n",
    "    for i in range(len(src_points)):\n",
    "        Average_x_1+=src_points[i][0]\n",
    "        Average_y_1+=src_points[i][1]\n",
    "        Average_x_2+=dst_points[i][0]\n",
    "        Average_y_2+=dst_points[i][1]\n",
    " \n",
    "    Average_x_1= Average_x_1 / len(src_points)\n",
    "    Average_y_1= Average_y_1 / len(src_points)\n",
    "    Average_x_2= Average_x_2 / len(src_points)\n",
    "    Average_y_2= Average_y_2 / len(src_points)\n",
    "\n",
    "    new_src_points=[]\n",
    "    new_dst_points=[]\n",
    "\n",
    "    for i in range(len(src_points)):\n",
    "\n",
    "        x1=src_points[i][0]-Average_x_1\n",
    "        y1=src_points[i][1]-Average_y_1\n",
    "        x2=dst_points[i][0]-Average_x_2\n",
    "        y2=dst_points[i][1]-Average_y_2\n",
    "     \n",
    "        new_src_points.append([x1,y1])\n",
    "        new_dst_points.append([x2,y2])\n",
    "\n",
    "    distancesrc=0\n",
    "    distancedst=0\n",
    "\n",
    "    for i in range(len(new_src_points)):\n",
    "        distancesrc += float(math.sqrt(new_src_points[i][0]**2 +   new_src_points[i][1]**2))\n",
    "        distancedst += float(math.sqrt(new_dst_points[i][0]**2 +   new_dst_points[i][1]**2))\n",
    "\n",
    "    lamda=  math.sqrt(2)/float(distancesrc)\n",
    "    lamda2=  math.sqrt(2)/float(distancedst)\n",
    "    t=np.array([[float(lamda),0,float(lamda)*(-Average_x_1)],[0,float(lamda),float(lamda)*(-Average_y_1)],[0,0,1]])\n",
    "    t2=np.array([[float(lamda2),0,float(lamda2)*(-Average_x_2)],[0,float(lamda2),float(lamda2)*(-Average_y_2)],[0,0,1]])\n",
    "    list=[]\n",
    "    for i in range(len(new_src_points)):\n",
    "        new_src_points[i][0]= lamda * new_src_points[i][0]\n",
    "        new_src_points[i][1]= lamda * new_src_points[i][1]\n",
    "        new_dst_points[i][0]= lamda2 * new_dst_points[i][0]\n",
    "        new_dst_points[i][1]= lamda2 * new_dst_points[i][1]\n",
    "    for i in range(len(new_src_points)):\n",
    "     \n",
    "        list.append([0,0,0,-new_src_points[i][0],-new_src_points[i][1],-1,new_dst_points[i][1]*new_src_points[i][0],new_dst_points[i][1]*new_src_points[i][1],new_dst_points[i][1]])\n",
    "        list.append([new_src_points[i][0],new_src_points[i][1],1,0,0,0,-new_dst_points[i][0]*new_src_points[i][0],-new_src_points[i][1]*new_dst_points[i][0],-new_dst_points[i][0]])\n",
    "    list=np.array(list)\n",
    "    w,u,vt=cv2.SVDecomp(np.asarray(list))\n",
    "    homography=[[vt[-1][0],vt[-1][1],vt[-1][2]],[vt[-1][3],vt[-1][4],vt[-1][5]],[vt[-1][6],vt[-1][7],vt[-1][8]]]\n",
    "    invT = inv(t2)\n",
    "\n",
    "    newHomograpy=np.dot(invT,homography)\n",
    "\n",
    "    return np.dot(newHomograpy,t)\n",
    "#---------Main Starts Here-----------------\n",
    "\n",
    "img1 = cv2.imread('img1.jpg')          \n",
    "img2 = cv2.imread('img2.jpg')\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create(contrastThreshold = 0.05 ,edgeThreshold = 10)\n",
    "\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "best = 999999\n",
    "temp_for_l=0\n",
    "keypoints_1 = []\n",
    "keypoints_2 = []\n",
    "difference = 0\n",
    "distance_point= 0\n",
    "\n",
    "for i in range (len(des1)):\n",
    "    for l in range (len(des2)):\n",
    "        for m in range (len(des1[0])):\n",
    "            difference += (des1[i][m]-des2[l][m])**2\n",
    "        distance_point = math.sqrt(difference)\n",
    "        difference =0\n",
    "        if (distance_point<best):\n",
    "            best=distance_point\n",
    "            temp_for_l = l\n",
    "    print (\"Matches are calculating, please wait... %\",i/len(des1)*100 )\n",
    "    if (kp1[i].pt not in keypoints_1 and kp2[temp_for_l].pt not in keypoints_2 ):\n",
    "        keypoints_1.append((kp1[i].pt))\n",
    "        keypoints_2.append((kp2[temp_for_l].pt))\n",
    "    temp_for_l = 0\n",
    "    best = 999999\n",
    "    \n",
    "Nransac=10000\n",
    "n=0\n",
    "numberOfinliersCopy=0\n",
    "lastSrc=[]\n",
    "lastDst=[]\n",
    "Inlier=[]\n",
    "\n",
    "keypoints_1=np.array(keypoints_1)\n",
    "keypoints_2=np.array(keypoints_2)\n",
    "#------------------RANSAC Starts here----------------------\n",
    "best_inlier=0\n",
    "while(n<Nransac):\n",
    " \n",
    "    numberOfinliers=0\n",
    "    random=np.random.randint(0,len(keypoints_1))\n",
    "    random2=np.random.randint(0,len(keypoints_1))\n",
    "    random3=np.random.randint(0,len(keypoints_1))\n",
    "    random4=np.random.randint(0,len(keypoints_1))\n",
    " \n",
    " \n",
    "    src_points=[(keypoints_1[random]),(keypoints_1[random2]),(keypoints_1[random3]),(keypoints_1[random4])]\n",
    "    dst_points=[(keypoints_2[random]),(keypoints_2[random2]),(keypoints_2[random3]),(keypoints_2[random4])]\n",
    " \n",
    "    src_points=np.array(src_points)\n",
    "    dst_points=np.array(dst_points)\n",
    "\n",
    "    Homography2=dlt(src_points,dst_points)\n",
    " \n",
    "    for x in range(len(keypoints_1)):\n",
    "        pointsList=np.dot(Homography2,np.array([[keypoints_1[x][0]],[keypoints_1[x][1]],[1]]))\n",
    "   \n",
    "        pointsList[0]=pointsList[0]/pointsList[2]\n",
    "        pointsList[1]=pointsList[1]/pointsList[2]\n",
    "        pointsList[2]=pointsList[2]/pointsList[2]\n",
    "        pointsList=np.array(pointsList)\n",
    "     \n",
    "\n",
    "        for y in range (len(keypoints_2)):\n",
    "           \n",
    "            if (math.sqrt((pointsList[0]-keypoints_2[y][0])**2+(pointsList[1]-keypoints_2[y][1])**2)<=3.0):\n",
    "                numberOfinliers+=1\n",
    "                break\n",
    "                 \n",
    "    inlierRatio= float(numberOfinliers / len(keypoints_1))\n",
    "    if(numberOfinliers>numberOfinliersCopy):\n",
    "            homography3=Homography2\n",
    "            best_inlier=numberOfinliers\n",
    "            Nransac=int((-2.0/float(math.log10(1.0-(float(inlierRatio**4))))) - 1.0)\n",
    "            n=0\n",
    " \n",
    "    n+=1\n",
    "    numberOfinliersCopy=best_inlier\n",
    "    print (\"RANSAC number is : \",Nransac)\n",
    "    print (\"Best Number of inlier is\",best_inlier)\n",
    "\n",
    "print (\"best inlier Ratio is:\",(best_inlier/len(keypoints_1))*100)\n",
    "\n",
    "Src=[]\n",
    "Dst=[]\n",
    "Src,Dst=findInlier(homography3,keypoints_1,keypoints_2)  # Find inlier with best homography\n",
    "\n",
    "n=0\n",
    "\n",
    "#------------------ loop with dlt to find better inliers-------------------\n",
    "previousSrc=[]\n",
    "previousDst=[]\n",
    "while(1):\n",
    " \n",
    "    betterHomo=dlt(Src,Dst)\n",
    "\n",
    "    previousSrc=np.copy(Src)\n",
    "    previousDst=np.copy(Dst)\n",
    "\n",
    "    Src = []\n",
    "    Dst = []\n",
    "    if (len(previousSrc) <= 4 or  len(previousDst) <= 4):\n",
    "        break\n",
    "    Src,Dst=findInlier(betterHomo,previousSrc,previousDst)\n",
    "   \n",
    "    if (len(Src)==len(previousSrc)): # When Src = scrcopy inliers are converge\n",
    "        break\n",
    "        \n",
    "        \n",
    "#--------------Draw rectangle-----------------\n",
    "\n",
    "bottom_right=np.dot(betterHomo,np.array([[455.0],[576.0],[1.0]]))\n",
    "top_left=np.dot(betterHomo,np.array([[160.0],[160.0],[1.0]]))\n",
    "\n",
    "top_left[0]=float(top_left[0]/top_left[2])\n",
    "top_left[1]=float(top_left[1]/top_left[2])\n",
    "\n",
    "bottom_right[0]=float(bottom_right[0]/bottom_right[2])\n",
    "bottom_right[1]=float(bottom_right[1]/bottom_right[2])\n",
    "\n",
    "\n",
    "detection = cv2.imread('img2.jpg')\n",
    "\n",
    "cv2.rectangle(detection,(top_left[0],top_left[1]),(bottom_right[0],bottom_right[1]),(0,0,255),5)\n",
    "\n",
    "cv2.imwrite(\"object detection.png\",detection)\n",
    "\n",
    "#Comment-1: SIFT algortihm: SIFT firstly use difference of gaussian to estimate minimum and maximum scale space.\n",
    "#Then determine keypoints candidates by eliminating low contrast points. After do keypoint orientation with first image gradients\n",
    "# finaly compute  descriptors with gradient  magnitude  and  orientation\n",
    "# ORB algorithm: ORB is using FAST keypoint detector and BRIEF descriptor.First determine the key points with using FAST.\n",
    "# FAST does not compute the orientation and rotation variant. It works with intensity differences between corners and center.\n",
    "# Then BRIEF descriptor calculate descriptors.\n",
    "# SIFT is  more scale invariant than ORB algorithm.\n",
    "# According to some researches on internet ORB algorithm much faster than SIFT algorithm but often SIFT algorithm find more keypoints\n",
    "# then ORB. ORB is faster than SIFT because ORB use hamming distance but SIFT use euclidian distance and SIFT algorithm do much\n",
    "# calculation and using more memory with 128-d descriptors.\n",
    "\n",
    "# Comment-2: I am using SIFT algorithm and i found nearest neighbour for each correspondence with euclidean distance.\n",
    "#SIFT descriptors are 128 dimensions. To find nearest neighbour in 128-d descriptor we must use euclidean distance\n",
    "# If a used ORB algortihm. ORB descripters are binery and to find nearest neighbour in ORB descriptor we must use hamming distance\n",
    "# Hamming distance gives difference between two binary numbers with xor\n",
    "\n",
    "\n",
    "# Comment-3: Our aim is in this part find potential inliers and find a inlier ratio to determine which homogrophy is better\n",
    "# If we set Euclidean distance threshold to smaller than the 3 pixels. we get less inliers and inlier ratio so our inlier ratio\n",
    "# will decrease. Ransac run time increase but maybe we can lost some good correspondences.\n",
    "\n",
    "# Comment-4 : Normalization is putting both points on the border which makes the solution more stable and puts it near from the center.\n",
    "# The source and target coordinate data are usually noisy without normalization. With normalization we solve this problem.\n",
    "# Basically normalization provides better handled points and calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
